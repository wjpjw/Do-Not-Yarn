# GPU-RT
为k8s上TensorFlow推理服务容器提供GPU metrics实时监控

## 编程范式与风格
1. 命名遵循camel casing，为了统一风格在wjp.h里把stl强行做了做alias。
2. 这个项目是不打算重用的业务代码，原创代码不使用namespace。
3. 采用C++14标准。
4. 尽可能让类似语句对齐（一堆等式的等号、struct的属性定义等）。
5. 每对.h/.cpp文件对应一个关键的类，文件名就是类名，与java风格类似，不过文件内部可以多一些辅助的类、struct、enum等。粒度比典型的c++项目稍低（leveldb, zeromq），又高于java。


## 异常与异常安全
1. 每当出现不可恢复异常时，立刻中止程序。C++中应该避免exit，它没有办法让操作系统知道资源生命周期结束并释放。正确的做法是在main里catch到抛出的异常，打印一下就立刻return EXIT_FAILURE，让操作系统了解一下。
2. 自定义异常完全没必要，就用runtime_error加一句话描述足够了。
3. 可恢复异常不应该抛出到莫名其妙的地方去解决，这会引发Martin Sustrik对异常的忧虑。我的看法是，既然可恢复，就代表它是正常代码分支，应该就地处理。类似C中的处理方式：if(err)handle_it();
4. Google禁用异常是因为历史包袱，新项目用异常利大于弊。
5. RAII值语义很容易写出异常安全的代码。在可以异常的代码调用前把RAII资源对象定义起来，一旦异常也不会发生资源泄露，因为这些RAII对象在代码块结束之后就自动析构了。

## 网络通信模型

1. monitor 1 : N gpurealtime
2. monitor用poll,在同一时间异步非阻塞地去读N个容器内的gpurealtime提供的gpu信息。
3. gpurealtime定期提供推送(push)，也不是pub-sub模式，只有一个接受推送的monitor。
4. 部署时gpurealtime应该放在不同容器内，通过k8s service暴露相同的端口号。测试时可以在localhost用不同端口测。
5. zeromq的socket是没有启动顺序问题的（比tcp），所以微服务形式存在的gpurealtime进程死了复活就行，根本不影响monitor的正常运转。monitor只在gpurealtime长期失联的情况下通知kubernetes复活某个gpurealtime服务。


## 心跳协议设计

心跳协议的实现应该遵循：
1. 与业务routine共享相同线程（从而验证该业务线程的存活）
2. 与业务message共享相同连接（从而验证该业务连接的存活）

TCP自带的keepalive心跳每隔一段时间（默认很长）发个包，避免网络中间设备（防火墙、NAT路由器）因为连接不活跃而踢掉连接。这种通信层的心跳机制是无法保证应用层的程序health check的（说不定conn还在，程序已经死锁、阻塞、百足之虫了），而且tcp要retry很多次，浪费很长时间才会确认断开——。

心跳协议在不同应用场景下合理间歇不同。

a) 像暗黑三这种，我目测3秒钟连不上就判定掉线重连了。
b) 而那种很长时间都不交流的沉默连接，则只需要隔很长时间问候一声，确定一下对方还在世。
c) 只是单纯要绕过防火墙，间歇应比较长，同时又小于防火墙死刑判定时间。

monitor的目的是提供实时监控，虽然垂询间隔可以是3s，5s，甚至30s。但为了可靠性，在gpurealtime端应该设计一个短间歇的心跳协议——monitor随时确保掌握集群中各容器的gpu状态，这个信息的实时性很关键，因为会被sched组件拿过去分配TensorFlow推理任务。

短暂间歇的问题是，sender和receiver之间网络如果不通畅就会立刻爆炸，我们的k8s overlay network基本没有中间设备，都是直连，所以没问题。

因此我把心跳间歇定为t=1s，死亡连接判定时间为2t=2s，假设推送间歇是6s，可以保证gpurealtime在挂了后的第2s就被monitor感知到，立刻通知k8s重启微服务——重启之后立刻就推送当前状态，因此实时性可以得到保证。

心跳消息默认用空字符串，也就是没有payload来表示。

